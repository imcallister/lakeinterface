{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067deb1-a0bd-4822-939c-2c1256e90d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datalake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664de47-b532-4afd-b632-10f88e8db8f6",
   "metadata": {},
   "source": [
    "## Datalake interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390df4bf-d926-44f7-ad19-d076fabdfaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "#| hide\n",
    "\n",
    "import boto3\n",
    "import polars as pl\n",
    "import s3fs\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "from lakeinterface.config import ConfigManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5904d701-920c-486a-b676-60671970e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "def most_recent(keys, prefix):\n",
    "    dates = [\n",
    "        o.replace(prefix, '').replace('data.parquet', '').replace('/', '')\n",
    "        for o in keys\n",
    "    ]\n",
    "    latest = max(parse(d) for d in dates).strftime('%Y%m%d')\n",
    "    return f'{prefix}/{latest}/data.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91459878-07c3-4219-afd2-62e2b60c0b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "\n",
    "class S3ObjectNotFound(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Datalake(object):\n",
    "    \"\"\"\n",
    "    A class to wrap interface to an AWS S3 datalake\n",
    "    Implemented as a singleton to reduce number of live sessions\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    session: a boto3 session\n",
    "    s3 : a boto3 S3 client\n",
    "    bucket : S3 bucket location of lake\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    __init__(config, profile='default'):\n",
    "        Initializes the AWS S3 client using AWS profile_name and dict of parameters from ConfigManager\n",
    "    \n",
    "    get_object(key):\n",
    "        Core method for loading objects using boto3 S3 client\n",
    "    \n",
    "    load_csv(key, delimiter=',', skiprows=None, line_terminator=None):\n",
    "        Loads csv object with S3 prefix = key\n",
    "    \n",
    "    load_json(key):\n",
    "        Loads json object with S3 prefix = key\n",
    "        \n",
    "    list_objects(prefix):\n",
    "        Lists all objects with S3 prefix = key\n",
    "    \n",
    "    save_json(path, data, timestamp=None):\n",
    "        Saves json object to specified path with an optional timestamp that will be inserted into path\n",
    "    \n",
    "    put_object(key, data, metadata={}):\n",
    "        Core method for saving objects using boto3 S3 client\n",
    "    \n",
    "    most_recent(prefix):\n",
    "        For a given S3 prefix returns object has most recent timestamp\n",
    "     \n",
    "    put(path, df, timestamp=None):\n",
    "        Saves a dataframe as parquet to specified path with an optional timestamp that will be inserted into path\n",
    "    \n",
    "    get(path):\n",
    "        Loads parquet object from specified path as a dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls, config, profile_name='default'):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(Datalake, cls).__new__(cls)\n",
    "            # Put any initialization here.\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self, config, profile_name='default'):\n",
    "        self.session = boto3.session.Session(profile_name=profile_name)\n",
    "        \n",
    "        self.bucket = config.get('bucket')\n",
    "        self.s3 = self.session.client('s3')\n",
    "        self.fs = s3fs.S3FileSystem(profile=profile_name)\n",
    "        \n",
    "    def get_object(self, key):\n",
    "        try:\n",
    "            return self.s3.get_object(Bucket=self.bucket, Key=key)\n",
    "        except Exception as e:\n",
    "            if e.response['Error']['Code'] == 'NoSuchKey':\n",
    "                raise S3ObjectNotFound('No S3 object with key = %s' % key)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    def load_csv(self,key, separator=',', skiprows=None, line_terminator=None):\n",
    "        obj = self.get_object(key)\n",
    "        if line_terminator:\n",
    "            return pl.read_csv(obj['Body'], separator=separator, lineterminator=line_terminator)\n",
    "        else:\n",
    "            return pl.read_csv(obj['Body'], separator=separator)\n",
    "    \n",
    "    \n",
    "    def load_json(self, key):\n",
    "        obj = self.get_object(key)\n",
    "        return json.loads(obj['Body'].read())\n",
    "    \n",
    "    def load_parquet(self, key):\n",
    "        obj = self.get_object(key)\n",
    "        return pl.read_parquet(BytesIO(obj['Body'].read()))\n",
    "    \n",
    "    def get(self, path):\n",
    "        try:\n",
    "            key = self.most_recent(path)\n",
    "        except Exception as e:\n",
    "            print(f'No objects found with path: {key}. {e}')\n",
    "            return None\n",
    "\n",
    "        return self.load_parquet(key)\n",
    "    \n",
    "    \n",
    "    def list_objects(self, prefix):\n",
    "        \n",
    "        paginator = self.s3.get_paginator('list_objects_v2')\n",
    "        pages = paginator.paginate(Bucket=self.bucket, Prefix=prefix)\n",
    "\n",
    "        return sum([[obj['Key'] for obj in page['Contents']] for page in pages], [])\n",
    "    \n",
    "\n",
    "    def save_json(self, path, data, timestamp=None):\n",
    "        if timestamp:\n",
    "            key = f'{path}/timestamp={timestamp}/data.json'\n",
    "        else:\n",
    "            key = f'{path}/data.json'\n",
    "\n",
    "        return self.put_object(key, json.dumps(data))\n",
    "        \n",
    "    def put_object(self, key, data, metadata={}):\n",
    "        try:\n",
    "            resp = self.s3.put_object(\n",
    "                Bucket=self.bucket,\n",
    "                Key=key,\n",
    "                Body=data\n",
    "            )\n",
    "            status_code = resp['ResponseMetadata']['HTTPStatusCode']\n",
    "            if status_code == 200:\n",
    "                return True\n",
    "            else:\n",
    "                raise Exception(f'Unknown error. Status code: {status_code}')\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Unknown error in put object for {key}. {str(e)}')\n",
    "\n",
    "    \n",
    "            \n",
    "    def put(self, path, df, timestamp=None):\n",
    "        if timestamp:\n",
    "            key = f'{path}/{timestamp}/data.parquet'\n",
    "        else:\n",
    "            key = f'{path}/data.parquet'\n",
    "\n",
    "        with self.fs.open(f'{self.bucket}/{key}', mode='wb') as f:\n",
    "            df.write_parquet(f)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def most_recent(self, prefix):\n",
    "        matched_objects = self.list_objects(prefix=prefix)\n",
    "        \n",
    "        if len(matched_objects) > 1:\n",
    "            try:\n",
    "                return most_recent(matched_objects, prefix)\n",
    "            except:\n",
    "                print(f'Multiple objects found for prefix {prefix}. Unable to find most recent.')\n",
    "                return None\n",
    "        elif len(matched_objects) == 0:\n",
    "            print(f'No objects found for prefix {prefix}')\n",
    "            return None\n",
    "        else:\n",
    "            return matched_objects[0]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c866ced-621c-4cdd-8308-a403bd4f9455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf95a1-7291-400f-a8e9-23db446351dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    A class to wrap interface to an AWS S3 datalake\n",
      "    Implemented as a singleton to reduce number of live sessions\n",
      "    ...\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    session: a boto3 session\n",
      "    s3 : a boto3 S3 client\n",
      "    bucket : S3 bucket location of lake\n",
      "    \n",
      "    Methods\n",
      "    -------\n",
      "    __init__(config, profile='default'):\n",
      "        Initializes the AWS S3 client using AWS profile_name and dict of parameters from ConfigManager\n",
      "    \n",
      "    get_object(key):\n",
      "        Core method for loading objects using boto3 S3 client\n",
      "    \n",
      "    load_csv(key, delimiter=',', skiprows=None, line_terminator=None):\n",
      "        Loads csv object with S3 prefix = key\n",
      "    \n",
      "    load_json(key):\n",
      "        Loads json object with S3 prefix = key\n",
      "        \n",
      "    list_objects(prefix):\n",
      "        Lists all objects with S3 prefix = key\n",
      "    \n",
      "    save_json(path, data, timestamp=None):\n",
      "        Saves json object to specified path with an optional timestamp that will be inserted into path\n",
      "    \n",
      "    put_object(key, data, metadata={}):\n",
      "        Core method for saving objects using boto3 S3 client\n",
      "    \n",
      "    most_recent(prefix):\n",
      "        For a given S3 prefix returns object has most recent timestamp\n",
      "     \n",
      "    put(path, df, timestamp=None):\n",
      "        Saves a dataframe as parquet to specified path with an optional timestamp that will be inserted into path\n",
      "    \n",
      "    get(path):\n",
      "        Loads parquet object from specified path as a dataframe\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(Datalake.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac6c76c-0edd-4e6c-89d4-9c2d3328a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgmgr = ConfigManager(profile='personal')\n",
    "cfg = cfgmgr.fetch_config('bankdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf620ae6-da95-4792-91a4-87e410ac2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake = Datalake(cfg, profile_name='personal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c88e7-d622-4c8d-99ba-f76c26783d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>col1</th><th>col2</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>3</td></tr><tr><td>2</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌──────┬──────┐\n",
       "│ col1 ┆ col2 │\n",
       "│ ---  ┆ ---  │\n",
       "│ i64  ┆ i64  │\n",
       "╞══════╪══════╡\n",
       "│ 1    ┆ 3    │\n",
       "│ 2    ┆ 4    │\n",
       "└──────┴──────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pl.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3989bf-c493-482c-864e-6b1f22292caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake.put('test/example1', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bfcb56-22a9-4f29-94f6-0aba765b5fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/example1/data.parquet', 'test/example2/data.parquet']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake.list_objects(prefix='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5cac35-1a60-4ec0-8133-2f75fe65ad3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>col1</th><th>col2</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>3</td></tr><tr><td>2</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌──────┬──────┐\n",
       "│ col1 ┆ col2 │\n",
       "│ ---  ┆ ---  │\n",
       "│ i64  ┆ i64  │\n",
       "╞══════╪══════╡\n",
       "│ 1    ┆ 3    │\n",
       "│ 2    ┆ 4    │\n",
       "└──────┴──────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake.get('test/example1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48794297-7bc6-43fd-aafa-e34c161cb0fd",
   "metadata": {},
   "source": [
    "### Testing polars\n",
    "\n",
    "There are multiple ways of having polars load & save data from S3. This was to test out approaches for which approach to take in the Datalake class defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83d1e4-8229-4d2b-987c-1b012e377152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec139470-78e7-4391-bbc3-0b0480ce5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(profile='personal')\n",
    "bucket = lake.bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54d114-1b30-487e-a198-8e7b761675dd",
   "metadata": {},
   "source": [
    "#### Reading parquet file I\n",
    "\n",
    "Doesn't work with scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8b2a8-27ce-49a0-a930-28a564755b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8260788917541504\n"
     ]
    }
   ],
   "source": [
    "path = 'test/example1/data.parquet'\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "dataset = pq.ParquetDataset(f\"s3://{bucket}/{path}\", filesystem=fs)\n",
    "df = pl.from_arrow(dataset.read())\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49429bce-05be-44e1-a2ac-ba4374eead94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>col1</th><th>col2</th><th>__index_level_0__</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>3</td><td>0</td></tr><tr><td>2</td><td>4</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌──────┬──────┬───────────────────┐\n",
       "│ col1 ┆ col2 ┆ __index_level_0__ │\n",
       "│ ---  ┆ ---  ┆ ---               │\n",
       "│ i64  ┆ i64  ┆ i64               │\n",
       "╞══════╪══════╪═══════════════════╡\n",
       "│ 1    ┆ 3    ┆ 0                 │\n",
       "│ 2    ┆ 4    ┆ 1                 │\n",
       "└──────┴──────┴───────────────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d47e4b-748a-42fb-baed-2f38bacb84cc",
   "metadata": {},
   "source": [
    "#### Reading parquet file II\n",
    "\n",
    "using pyarrow dataset to specify format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6fd4a7-df93-4462-a24d-c836d49cd2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌──────┬──────┬───────────────────┐\n",
      "│ col1 ┆ col2 ┆ __index_level_0__ │\n",
      "│ ---  ┆ ---  ┆ ---               │\n",
      "│ i64  ┆ i64  ┆ i64               │\n",
      "╞══════╪══════╪═══════════════════╡\n",
      "│ 1    ┆ 3    ┆ 0                 │\n",
      "│ 2    ┆ 4    ┆ 1                 │\n",
      "└──────┴──────┴───────────────────┘\n",
      "2.759658098220825\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "dataset2 = ds.dataset(f\"s3://{bucket}/{path}\", filesystem=fs, format='parquet')\n",
    "df_parquet = pl.scan_pyarrow_dataset(dataset2)\n",
    "\n",
    "print(df_parquet.collect().head())\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc06f3-f44a-447a-9606-cc26aadac231",
   "metadata": {},
   "source": [
    "#### Reading parquet file III\n",
    "\n",
    "using boto3 get_object\n",
    "\n",
    "Doesn't allow scanning but approach works for csv and json files too. Appears to be quicker too\n",
    "\n",
    "This is first choice and an easy switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e702c12-8670-447e-b629-6f74e4334277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2696380615234375\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "resp = lake.get_object('test/example2/data.parquet')\n",
    "df = pl.read_parquet(BytesIO(resp['Body'].read()))\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c36b1f-4048-4554-85b5-ddc7f3766b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f1136-0d28-4eb5-88e7-20bb7f400a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_pth = 'banks/call_reports/raw/20210331/FFIEC CDR Call Bulk POR 03312021.txt'\n",
    "\n",
    "resp = lake.get_object(csv_pth)\n",
    "df = pl.read_csv(BytesIO(resp['Body'].read()), separator='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201e5108-9107-4b6f-90d7-3d8d3798c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>IDRSSD</th><th>FDIC Certificate Number</th><th>OCC Charter Number</th><th>OTS Docket Number</th><th>Primary ABA Routing Number</th><th>Financial Institution Name</th><th>Financial Institution Address</th><th>Financial Institution City</th><th>Financial Institution State</th><th>Financial Institution Zip Code</th><th>Financial Institution Filing Type</th><th>Last Date/Time Submission Updated On</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>37</td><td>10057</td><td>0</td><td>16553</td><td>61107146</td><td>&quot;BANK OF HANCOC…</td><td>&quot;12855 BROAD ST…</td><td>&quot;SPARTA&quot;</td><td>&quot;GA&quot;</td><td>31087</td><td>51</td><td>&quot;2021-04-12T14:…</td></tr><tr><td>242</td><td>3850</td><td>0</td><td>0</td><td>81220537</td><td>&quot;FIRST COMMUNIT…</td><td>&quot;260 FRONT STRE…</td><td>&quot;XENIA&quot;</td><td>&quot;IL&quot;</td><td>62899</td><td>51</td><td>&quot;2021-04-16T14:…</td></tr><tr><td>279</td><td>28868</td><td>0</td><td>2523</td><td>311972526</td><td>&quot;MINEOLA COMMUN…</td><td>&quot;215 W BROAD &quot;</td><td>&quot;MINEOLA&quot;</td><td>&quot;TX&quot;</td><td>75773</td><td>51</td><td>&quot;2021-05-03T08:…</td></tr><tr><td>354</td><td>14083</td><td>0</td><td>0</td><td>101107475</td><td>&quot;BISON STATE BA…</td><td>&quot;223 MAIN STREE…</td><td>&quot;BISON&quot;</td><td>&quot;KS&quot;</td><td>67520</td><td>51</td><td>&quot;2021-04-30T04:…</td></tr><tr><td>457</td><td>10202</td><td>0</td><td>0</td><td>91208332</td><td>&quot;LOWRY STATE BA…</td><td>&quot;400 FLORENCE A…</td><td>&quot;LOWRY&quot;</td><td>&quot;MN&quot;</td><td>56349</td><td>51</td><td>&quot;2021-04-30T15:…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 12)\n",
       "┌────────┬────────────┬────────────┬────────┬───┬────────────┬────────────┬────────────┬───────────┐\n",
       "│ IDRSSD ┆ FDIC Certi ┆ OCC        ┆ OTS    ┆ … ┆ Financial  ┆ Financial  ┆ Financial  ┆ Last      │\n",
       "│ ---    ┆ ficate     ┆ Charter    ┆ Docket ┆   ┆ Institutio ┆ Institutio ┆ Institutio ┆ Date/Time │\n",
       "│ i64    ┆ Number     ┆ Number     ┆ Number ┆   ┆ n State    ┆ n Zip Code ┆ n Filing   ┆ Submissio │\n",
       "│        ┆ ---        ┆ ---        ┆ ---    ┆   ┆ ---        ┆ ---        ┆ Typ…       ┆ n Update… │\n",
       "│        ┆ i64        ┆ i64        ┆ i64    ┆   ┆ str        ┆ i64        ┆ ---        ┆ ---       │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆ i64        ┆ str       │\n",
       "╞════════╪════════════╪════════════╪════════╪═══╪════════════╪════════════╪════════════╪═══════════╡\n",
       "│ 37     ┆ 10057      ┆ 0          ┆ 16553  ┆ … ┆ GA         ┆ 31087      ┆ 51         ┆ 2021-04-1 │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆            ┆ 2T14:52:3 │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆            ┆ 8         │\n",
       "│ 242    ┆ 3850       ┆ 0          ┆ 0      ┆ … ┆ IL         ┆ 62899      ┆ 51         ┆ 2021-04-1 │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆            ┆ 6T14:37:2 │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆            ┆ 3         │\n",
       "│ 279    ┆ 28868      ┆ 0          ┆ 2523   ┆ … ┆ TX         ┆ 75773      ┆ 51         ┆ 2021-05-0 │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆            ┆ 3T08:47:0 │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆            ┆ 2         │\n",
       "│ 354    ┆ 14083      ┆ 0          ┆ 0      ┆ … ┆ KS         ┆ 67520      ┆ 51         ┆ 2021-04-3 │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆            ┆ 0T04:25:0 │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆            ┆ 3         │\n",
       "│ 457    ┆ 10202      ┆ 0          ┆ 0      ┆ … ┆ MN         ┆ 56349      ┆ 51         ┆ 2021-04-3 │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆            ┆ 0T15:21:5 │\n",
       "│        ┆            ┆            ┆        ┆   ┆            ┆            ┆            ┆ 3         │\n",
       "└────────┴────────────┴────────────┴────────┴───┴────────────┴────────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd483b-45e7-4eed-9678-74e479e7634f",
   "metadata": {},
   "source": [
    "#### Writing parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135cbb42-afbc-4295-876f-837ed7ffe65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>col1</th><th>col2</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>3</td></tr><tr><td>2</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌──────┬──────┐\n",
       "│ col1 ┆ col2 │\n",
       "│ ---  ┆ ---  │\n",
       "│ i64  ┆ i64  │\n",
       "╞══════╪══════╡\n",
       "│ 1    ┆ 3    │\n",
       "│ 2    ┆ 4    │\n",
       "└──────┴──────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pl.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b62e75-2d3f-4c28-913d-9ecc49912105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6675841808319092\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "with fs.open(f'{bucket}/test/example3/data.parquet', mode='wb') as f:\n",
    "    df.write_parquet(f)\n",
    "    \n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188629c4-e128-44c0-9a1f-c2ef477aa781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌──────┬──────┐\n",
      "│ col1 ┆ col2 │\n",
      "│ ---  ┆ ---  │\n",
      "│ i64  ┆ i64  │\n",
      "╞══════╪══════╡\n",
      "│ 1    ┆ 3    │\n",
      "│ 2    ┆ 4    │\n",
      "└──────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "path = 'test/example3/data.parquet'\n",
    "dataset2 = ds.dataset(f\"s3://{bucket}/{path}\", filesystem=fs, format='parquet')\n",
    "df_parquet = pl.scan_pyarrow_dataset(dataset2)\n",
    "print(df_parquet.collect().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1b5ce-379d-41db-a18f-9765a0f6876e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
